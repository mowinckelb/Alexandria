import { createGroq } from '@ai-sdk/groq';
import { createTogetherAI } from '@ai-sdk/togetherai';
import { generateText } from 'ai';

const groq = createGroq({ apiKey: process.env.GROQ_API_KEY });
const togetherai = createTogetherAI({ apiKey: process.env.TOGETHER_API_KEY });

/**
 * Feedback entry from the database
 */
export interface FeedbackEntry {
  id: string;
  prompt: string;
  response: string;
  feedback: number;  // Binary: +1 (good) or -1 (bad)
  comment?: string;
}

/**
 * Synthetic preference pair generated by RLAIF
 */
export interface SyntheticPreferencePair {
  prompt: string;
  chosen: string;
  rejected: string;
  confidence: number;      // How confident the AI is in this preference
  reasoning: string;       // Why this was chosen over rejected
  source: 'rlaif';
}

/**
 * RLAIF Amplifier: Uses AI to convert sparse human feedback into dense preference pairs
 * 
 * Key insight: Before migration, we can use the OLD model + an LLM judge to generate
 * MORE preference pairs, converting implicit learned preferences into explicit data.
 */
export class RLAIFAmplifier {
  /**
   * Analyze existing feedback to extract preference patterns
   * Returns natural language rules that can guide synthetic pair generation
   */
  async extractPreferencePatterns(feedback: FeedbackEntry[]): Promise<{
    positivePatterns: string[];
    negativePatterns: string[];
    summary: string;
  }> {
    const positiveExamples = feedback
      .filter(f => f.feedback >= 1)
      .slice(0, 20)
      .map(f => `Prompt: "${f.prompt.slice(0, 100)}..."\nResponse: "${f.response.slice(0, 200)}..."\nRating: +${f.feedback}${f.comment ? `\nComment: ${f.comment}` : ''}`)
      .join('\n\n---\n\n');

    const negativeExamples = feedback
      .filter(f => f.feedback <= -1)
      .slice(0, 20)
      .map(f => `Prompt: "${f.prompt.slice(0, 100)}..."\nResponse: "${f.response.slice(0, 200)}..."\nRating: ${f.feedback}${f.comment ? `\nComment: ${f.comment}` : ''}`)
      .join('\n\n---\n\n');

    const { text } = await generateText({
      model: groq('llama-3.3-70b-versatile'),
      messages: [
        {
          role: 'system',
          content: 'You are an expert at analyzing human preferences in AI responses. Extract clear patterns.'
        },
        {
          role: 'user',
          content: `Analyze this feedback data to extract preference patterns.

POSITIVELY RATED RESPONSES:
${positiveExamples || '(none provided)'}

NEGATIVELY RATED RESPONSES:
${negativeExamples || '(none provided)'}

Extract:
1. What patterns make responses GOOD (rated +1 or +2)?
2. What patterns make responses BAD (rated -1 or -2)?
3. A summary of this user's overall preferences.

Output as JSON:
{
  "positivePatterns": ["pattern 1", "pattern 2", ...],
  "negativePatterns": ["pattern 1", "pattern 2", ...],
  "summary": "Overall preference summary"
}`
        }
      ]
    });

    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) throw new Error('No JSON found');
      return JSON.parse(jsonMatch[0]);
    } catch {
      return {
        positivePatterns: ['Authentic, natural responses', 'Matching the expected tone'],
        negativePatterns: ['Generic AI-sounding responses', 'Overly formal or stiff'],
        summary: 'User prefers authentic, natural responses over generic AI output.'
      };
    }
  }

  /**
   * Generate synthetic preference pairs using the old model + AI judge
   * 
   * Process:
   * 1. Generate diverse prompts
   * 2. Get multiple responses from old model (temperature variance)
   * 3. Use AI judge to rank responses based on learned preference patterns
   * 4. Create preference pairs from rankings
   */
  async generateSyntheticPairs(
    sourceModelId: string,
    preferencePatterns: { positivePatterns: string[]; negativePatterns: string[]; summary: string },
    prompts: string[],
    onProgress?: (completed: number, total: number) => void
  ): Promise<SyntheticPreferencePair[]> {
    const pairs: SyntheticPreferencePair[] = [];
    
    for (let i = 0; i < prompts.length; i++) {
      const prompt = prompts[i];
      
      try {
        // Generate 2-3 responses with different temperatures
        const responses = await this.generateVariedResponses(sourceModelId, prompt);
        
        if (responses.length < 2) continue;
        
        // Use AI judge to rank and create pairs
        const rankedPairs = await this.judgeAndRank(
          prompt,
          responses,
          preferencePatterns
        );
        
        pairs.push(...rankedPairs);
      } catch (error) {
        console.error(`Failed to generate pair for prompt: ${prompt.slice(0, 50)}...`, error);
      }
      
      if (onProgress) {
        onProgress(i + 1, prompts.length);
      }
    }
    
    return pairs;
  }

  /**
   * Generate multiple responses from the source model with temperature variance
   */
  private async generateVariedResponses(
    modelId: string,
    prompt: string
  ): Promise<string[]> {
    const temperatures = [0.3, 0.7, 1.0];
    const responses: string[] = [];
    
    for (const temp of temperatures) {
      try {
        const { text } = await generateText({
          model: togetherai(modelId),
          messages: [
            { role: 'system', content: 'You are a digital ghost. Respond authentically.' },
            { role: 'user', content: prompt }
          ],
          temperature: temp
        });
        
        if (text && text.length > 20) {
          responses.push(text);
        }
      } catch {
        // Skip failed generations
      }
    }
    
    return responses;
  }

  /**
   * Use AI judge to rank responses and create preference pairs
   */
  private async judgeAndRank(
    prompt: string,
    responses: string[],
    patterns: { positivePatterns: string[]; negativePatterns: string[]; summary: string }
  ): Promise<SyntheticPreferencePair[]> {
    const { text } = await generateText({
      model: groq('llama-3.3-70b-versatile'),
      messages: [
        {
          role: 'system',
          content: `You are a preference judge. You understand what makes responses good or bad based on learned patterns.

GOOD RESPONSE PATTERNS:
${patterns.positivePatterns.map((p, i) => `${i + 1}. ${p}`).join('\n')}

BAD RESPONSE PATTERNS:
${patterns.negativePatterns.map((p, i) => `${i + 1}. ${p}`).join('\n')}

USER PREFERENCE SUMMARY:
${patterns.summary}`
        },
        {
          role: 'user',
          content: `Rank these responses to the prompt and explain your reasoning.

PROMPT: "${prompt}"

${responses.map((r, i) => `RESPONSE ${i + 1}:\n"${r}"`).join('\n\n')}

Output JSON with rankings (1 = best):
{
  "rankings": [
    {"response_index": 0, "rank": 1, "reasoning": "why this is best/worst"},
    {"response_index": 1, "rank": 2, "reasoning": "..."},
    ...
  ],
  "confidence": 0.0-1.0
}`
        }
      ]
    });

    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) return [];
      
      const result = JSON.parse(jsonMatch[0]);
      const rankings = result.rankings.sort((a: { rank: number }, b: { rank: number }) => a.rank - b.rank);
      const confidence = result.confidence || 0.7;
      
      // Create preference pairs: best vs worst, best vs middle, etc.
      const pairs: SyntheticPreferencePair[] = [];
      
      if (rankings.length >= 2) {
        // Best vs Worst
        const best = rankings[0];
        const worst = rankings[rankings.length - 1];
        
        pairs.push({
          prompt,
          chosen: responses[best.response_index],
          rejected: responses[worst.response_index],
          confidence,
          reasoning: `Chosen: ${best.reasoning}. Rejected: ${worst.reasoning}`,
          source: 'rlaif'
        });
      }
      
      return pairs;
    } catch {
      return [];
    }
  }

  /**
   * Generate diverse prompts for RLAIF amplification
   * Focuses on edge cases and preference-revealing situations
   */
  async generateAmplificationPrompts(
    existingFeedback: FeedbackEntry[],
    count: number
  ): Promise<string[]> {
    // Extract topics from existing feedback
    const feedbackTopics = existingFeedback
      .slice(0, 30)
      .map(f => f.prompt)
      .join('\n');

    const { text } = await generateText({
      model: groq('llama-3.1-8b-instant'),
      messages: [
        {
          role: 'system',
          content: 'Generate diverse prompts for preference learning. Focus on edge cases and situations where style/tone choices matter.'
        },
        {
          role: 'user',
          content: `Based on these existing prompts that received feedback:
${feedbackTopics.slice(0, 3000)}

Generate ${count} NEW prompts that would reveal personality preferences. Include:
- Similar topics but different angles
- Edge cases (emotional, controversial, ambiguous)
- Situations where tone/style choices matter
- Mix of: questions, requests, scenarios, opinions

Output one prompt per line, no numbering:`
        }
      ]
    });

    return text
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 15 && !line.match(/^\d+[\.\)]/))
      .slice(0, count);
  }

  /**
   * Full RLAIF amplification pipeline
   * Converts sparse feedback into dense preference pairs before migration
   */
  async amplify(
    sourceModelId: string,
    feedback: FeedbackEntry[],
    targetPairCount: number,
    onProgress?: (phase: string, completed: number, total: number) => void
  ): Promise<{
    syntheticPairs: SyntheticPreferencePair[];
    preferencePatterns: { positivePatterns: string[]; negativePatterns: string[]; summary: string };
  }> {
    // Phase 1: Extract preference patterns
    if (onProgress) onProgress('extracting_patterns', 0, 1);
    const preferencePatterns = await this.extractPreferencePatterns(feedback);
    if (onProgress) onProgress('extracting_patterns', 1, 1);
    
    // Phase 2: Generate amplification prompts
    if (onProgress) onProgress('generating_prompts', 0, targetPairCount);
    const prompts = await this.generateAmplificationPrompts(feedback, targetPairCount);
    if (onProgress) onProgress('generating_prompts', prompts.length, targetPairCount);
    
    // Phase 3: Generate synthetic pairs
    const syntheticPairs = await this.generateSyntheticPairs(
      sourceModelId,
      preferencePatterns,
      prompts,
      (completed, total) => {
        if (onProgress) onProgress('generating_pairs', completed, total);
      }
    );
    
    return { syntheticPairs, preferencePatterns };
  }
}

